{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request\n",
    "import datetime\n",
    "import gzip\n",
    "import shutil\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from math import cos, asin, sqrt\n",
    "import datetime\n",
    "import sklearn\n",
    "import sys\n",
    "\n",
    "listing_col  = ['id', ## om het nog te traceren\n",
    "               'host_id',## om het nog te traceren\n",
    "               'listing_url',\n",
    "               'name',\n",
    "               'price',\n",
    "#                'summary', ## Heel vaak niet gevuld, heeft te veel invloed op het uiteindelijke resultaat\n",
    "               'host_name',\n",
    "#                'host_about',\n",
    "               'description',\n",
    "               'neighbourhood_cleansed', # om het nog te aggrereen\n",
    "#                'property_type',\n",
    "               'room_type',\n",
    "               'beds',\n",
    "               'bedrooms',\n",
    "               'bathrooms',\n",
    "               'accommodates',\n",
    "               'latitude',  # nog even erin laten\n",
    "               'longitude'  # nog even erin laten\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TfidfVectorizer', 1056),\n",
       " ('Out', 240),\n",
       " ('listing_col', 184),\n",
       " ('cosine_similarity', 136),\n",
       " ('linear_kernel', 136),\n",
       " ('In', 96),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('preprocessing', 80),\n",
       " ('sparse', 80),\n",
       " ('asin', 72),\n",
       " ('cos', 72),\n",
       " ('sqrt', 72),\n",
       " ('get_ipython', 64),\n",
       " ('exit', 56),\n",
       " ('quit', 56)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Handige cell om inzicht in groote van objecten te weergeven\n",
    "\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the data of 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "url = 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2018-01-10/data/listings.csv.gz'\n",
    "filename = 'listings_2018-01-10.csv.gz'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "unfilled = gzip.open(filename)\n",
    "df_listings = pd.read_csv(unfilled, usecols=listing_col)\n",
    "df_listings['publicatie'] = '2018-01-10'\n",
    "item = \"listings\" \n",
    "            \n",
    "\n",
    "our_dates= []\n",
    "start = datetime.datetime.strptime(\"11-01-2018\", \"%d-%m-%Y\")  # we can change this\n",
    "end = datetime.datetime.strptime(\"31-12-2018\", \"%d-%m-%Y\")    # we can change this\n",
    "date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end-start).days)]\n",
    "\n",
    "for date in date_generated:\n",
    "    our_dates.append(date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "for date in our_dates:\n",
    "    url = \"http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/\" +date+ \"/data/\"+item+\".csv.gz\"\n",
    "    filename = item +\"_\"+ date +\".csv.gz\" \n",
    "    file_python = item +\"_\"+ date\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print(\"found : \" + date)\n",
    "        unfilled = gzip.open(filename)\n",
    "#         df_reviews[file_python] = pd.read_csv(unfilled)\n",
    "        temp = pd.read_csv(unfilled, usecols=listing_col)\n",
    "        temp['publicatie'] = date\n",
    "        \n",
    "        df_listings.append(temp)\n",
    "        \n",
    "        \n",
    "    except urllib.error.URLError as e:\n",
    "        print(e.reason) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading only one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2019-01-13/data/listings.csv.gz'\n",
    "filename = 'listings_2019-01-13.csv.gz'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "unfilled = gzip.open(filename)\n",
    "df_listings = pd.read_csv(unfilled, usecols=listing_col)\n",
    "# df_listings['publicatie'] = '2019-01-13'\n",
    "\n",
    "del unfilled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set verdeelsleutel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdeelsleutel_description        =0.4\n",
    "verdeelsleutel_name               =0.1\n",
    "verdeelsleutel_price              =0.05\n",
    "verdeelsleutel_location           =0.4\n",
    "verdeelsleutel_listing_attributes =0.05\n",
    "# 40%, name 10%, price 5%, location 40%, amenities 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_helper = list(range(0, len(df_listings), 1000))\n",
    "df_listings['bedrooms'].fillna((df_listings['bedrooms'].mean()), inplace=True)\n",
    "df_listings['beds'].fillna((df_listings['beds'].mean()), inplace=True)\n",
    "df_listings['bathrooms'].fillna((df_listings['bathrooms'].mean()), inplace=True)\n",
    "df_listings['price'] = pd.to_numeric(df_listings['price'].str.replace(',','').str.replace('$',''))\n",
    "df_listings.description = df_listings.description.fillna('')\n",
    "df_listings.host_name = df_listings.host_name.fillna('')\n",
    "df_listings.name = df_listings.name.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Description and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_cosine_function (columname, listing_id_column, verdeel_sleutel= 1):\n",
    "    \"\"\" This function turns a non numerical column into a cosine simalartiy matrix using tfidf \"\"\"\n",
    "    \n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(columname)\n",
    "\n",
    "    cosine_simalarity_array = linear_kernel(tfidf_matrix,tfidf_matrix)\n",
    "    np.fill_diagonal(cosine_simalarity_array, 0)\n",
    "    output = pd.DataFrame(cosine_simalarity_array)\n",
    "    output.rename(index=listing_id_column , inplace = True)\n",
    "    output.rename(columns= listing_id_column, inplace = True)\n",
    "    del cosine_simalarity_array      \n",
    "    return output * verdeel_sleutel\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "description =tfidf_cosine_function(df_listings.description, df_listings.id,verdeelsleutel_description )\n",
    "name        =tfidf_cosine_function(df_listings.name, df_listings.id , verdeelsleutel_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Listing attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memommery issues door amnestiesen propertytype\n",
    "listing_attributes = df_listings[['accommodates','bathrooms','bedrooms','beds', 'room_type']]\n",
    "listing_attributes =pd.get_dummies(listing_attributes, columns=['room_type'])\n",
    "cosine_simalarity_array = cosine_similarity(listing_attributes,listing_attributes)\n",
    "np.fill_diagonal(cosine_simalarity_array, 0)\n",
    "listing_attributes = pd.DataFrame(cosine_simalarity_array * verdeelsleutel_listing_attributes)\n",
    "listing_attributes.rename(index= df_listings.id , inplace = True)\n",
    "listing_attributes.rename(columns= df_listings.id, inplace = True)\n",
    "del cosine_simalarity_array    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bezig met row  0 van de  19910 current time:  2019-01-21 12:13:09.576212\n",
      "Bezig met row  1000 van de  19910 current time:  2019-01-21 12:13:38.009675\n",
      "Bezig met row  2000 van de  19910 current time:  2019-01-21 12:14:06.943292\n",
      "Bezig met row  3000 van de  19910 current time:  2019-01-21 12:14:36.158152\n",
      "Bezig met row  4000 van de  19910 current time:  2019-01-21 12:15:06.187835\n",
      "Bezig met row  5000 van de  19910 current time:  2019-01-21 12:15:33.492720\n",
      "Bezig met row  6000 van de  19910 current time:  2019-01-21 12:16:01.113821\n",
      "Bezig met row  7000 van de  19910 current time:  2019-01-21 12:16:28.909510\n",
      "Bezig met row  8000 van de  19910 current time:  2019-01-21 12:16:56.815842\n",
      "Bezig met row  9000 van de  19910 current time:  2019-01-21 12:17:25.869161\n",
      "Bezig met row  10000 van de  19910 current time:  2019-01-21 12:17:52.995609\n",
      "Bezig met row  11000 van de  19910 current time:  2019-01-21 12:18:20.902944\n",
      "Bezig met row  12000 van de  19910 current time:  2019-01-21 12:18:48.205959\n",
      "Bezig met row  13000 van de  19910 current time:  2019-01-21 12:19:15.867938\n",
      "Bezig met row  14000 van de  19910 current time:  2019-01-21 12:19:43.104123\n",
      "Bezig met row  15000 van de  19910 current time:  2019-01-21 12:20:10.828939\n",
      "Bezig met row  16000 van de  19910 current time:  2019-01-21 12:20:39.217014\n",
      "Bezig met row  17000 van de  19910 current time:  2019-01-21 12:21:06.974812\n",
      "Bezig met row  18000 van de  19910 current time:  2019-01-21 12:21:34.754474\n",
      "Bezig met row  19000 van de  19910 current time:  2019-01-21 12:22:02.657888\n"
     ]
    }
   ],
   "source": [
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295     #Pi/180\n",
    "    a = 0.5 - cos((lat2 - lat1) * p)/2 + cos(lat1 * p) * cos(lat2 * p) * (1 - cos((lon2 - lon1) * p)) / 2\n",
    "    return 12742 * asin(sqrt(a)) #2*R*asin...\n",
    "\n",
    "# distance(52.36755,4.9414,53.390225,4.873924) ## voorbeeldje\n",
    "\n",
    "tuple_set = list(zip(df_listings.latitude, df_listings.longitude)) ## list met alle tuples\n",
    "\n",
    "matrix = np.zeros((len(tuple_set), len(tuple_set))) ## iniatilize the array\n",
    "\n",
    "for i in range(len(tuple_set)):  \n",
    "    for j in range(len(tuple_set)):\n",
    "        matrix[i][j] = abs(distance(*tuple_set[i], *tuple_set[j]))\n",
    "    if i in print_helper:\n",
    "        print(\"Bezig met row \", i, \"van de \", len(tuple_set), \"current time: \",datetime.datetime.now())\n",
    "\n",
    "        \n",
    "loc = sklearn.preprocessing.minmax_scale(matrix, feature_range=(0, 1), axis=1, copy=True)\n",
    "location = [1] - loc\n",
    "np.fill_diagonal(location, 0)\n",
    "location = pd.DataFrame(location * verdeelsleutel_location)       \n",
    "location.rename(index= df_listings.id , inplace = True)\n",
    "location.rename(columns= df_listings.id, inplace = True)\n",
    "\n",
    "del distance\n",
    "del matrix\n",
    "del loc\n",
    "del tuple_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bezig met row  0 van de  19910 current time:  2019-01-21 12:22:59.523753\n",
      "Bezig met row  1000 van de  19910 current time:  2019-01-21 12:23:29.139574\n",
      "Bezig met row  2000 van de  19910 current time:  2019-01-21 12:23:58.846092\n"
     ]
    }
   ],
   "source": [
    "extractedData = df_listings.loc[:,['price']].values\n",
    "\n",
    "\n",
    "# Uitgezet wegens performance redenen\n",
    "# for i in range(1,len(extractedData)):\n",
    "#     newrow = abs(extractedData.T - extractedData[i])\n",
    "#     A = np.vstack([A, newrow])\n",
    "#     if i in print_helper:\n",
    "#         print(\"Bezig met row \", i, \"van de \", len(extractedData), \"current time: \",datetime.datetime.now())\n",
    "\n",
    "matrix2 = np.zeros((len(extractedData), len(extractedData))) ## iniatilize the array\n",
    "        \n",
    "for i in range(len(extractedData)):  \n",
    "    for j in range(len(extractedData)):\n",
    "        matrix2[i][j] = abs(extractedData[i] - extractedData[j])\n",
    "    if i in print_helper:\n",
    "        print(\"Bezig met row \", i, \"van de \", len(extractedData), \"current time: \",datetime.datetime.now())\n",
    "\n",
    "price = sklearn.preprocessing.minmax_scale(matrix2, feature_range=(0, 1), axis=1, copy=True)\n",
    "price = [1] - price\n",
    "np.fill_diagonal(price, 0)\n",
    "price = pd.DataFrame(price * verdeelsleutel_price)  \n",
    "price.rename(index= df_listings.id , inplace = True)\n",
    "price.rename(columns= df_listings.id, inplace = True)\n",
    "\n",
    "del matrix2\n",
    "del extractedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add all the frames together in one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helaas loop ik tegen memomery issues aan, daarom verwijder ik de helft van elke frame, deze zou daarna opnieuw gedraaid moeten worden\n",
    "\n",
    "eerste_helft = 1\n",
    "tweede_helft = 0\n",
    "derde_helft  = 0\n",
    "\n",
    "if eerste_helft == 1:\n",
    "    description        = description.iloc[0:8000,:]\n",
    "    price              = price.iloc[0:8000,:]\n",
    "    listing_attributes = listing_attributes.iloc[0:8000,:]\n",
    "    location           = location.iloc[0:8000,:]\n",
    "    name               = name.iloc[0:8000,:]\n",
    "\n",
    "if tweede_helft == 1:\n",
    "    description        = description.iloc[8000:15000,]\n",
    "    price              = price.iloc[8000:15000,]\n",
    "    listing_attributes = listing_attributes.iloc[8000:15000,]\n",
    "    location           = location.iloc[8000:15000,]\n",
    "    name               = name.iloc[8000:15000,]\n",
    "\n",
    "if derde_helft == 1:\n",
    "    description        = description.iloc[15000:,:]\n",
    "    price              = price.iloc[15000:,:]\n",
    "    listing_attributes = listing_attributes.iloc[15000:,:]\n",
    "    location           = location.iloc[15000:,:]\n",
    "    name               = name.iloc[15000:,:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = description + name + price + location + listing_attributes\n",
    "result = description.add(name)\n",
    "result = result.add(location)\n",
    "result = result.add(price)\n",
    "result = result.add(listing_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the highest score per id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_matching_id = result.idxmax()\n",
    "match_value = result.max(axis=1)\n",
    "# del result\n",
    "match = pd.DataFrame({'best_matching_id':best_matching_id, 'match_value':match_value})\n",
    "match =match.sort_values(by=['match_value'], ascending=False)\n",
    "match_df = match.sort_values(by=['match_value'], ascending=False).reset_index()\n",
    "match_df.rename(columns = {'index':'id'}, inplace = True)\n",
    "\n",
    "## Enkel de matches overhouden met match_value > 70\n",
    "match_df = match_df[match_df['match_value'] > 0.7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only to show the urls\n",
    "\n",
    "result = pd.merge(match_df,\n",
    "                 df_listings[['id', 'listing_url', 'host_id']],\n",
    "                 on='id')\n",
    "result.head()\n",
    "\n",
    "result = pd.merge(result,\n",
    "                 df_listings[['id', 'listing_url', 'host_id']],\n",
    "                 left_on='best_matching_id', right_on = 'id')\n",
    "\n",
    "\n",
    "result.head()\n",
    "\n",
    "result_filter = result[result.host_id_x != result.host_id_y]\n",
    "\n",
    "def make_clickable(val):\n",
    "    # target _blank to open new window\n",
    "    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "\n",
    "result_filter = result_filter.sort_values(by=['match_value'], ascending=False)\n",
    "result_filter.style.format({'listing_url_x': make_clickable,'listing_url_y': make_clickable })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find corresponding feature contributions\n",
    "list_holder_attr  = []\n",
    "list_holder_price = []\n",
    "list_holder_name  = []\n",
    "list_holder_desc  = []\n",
    "list_holder_loc   = []\n",
    "\n",
    "for index, row in match_df.iterrows():\n",
    "    idnr = row['id']\n",
    "    best_match = row['best_matching_id']\n",
    "    list_holder_price.append(round(price.loc[idnr,best_match]/verdeelsleutel_price,3))\n",
    "    list_holder_loc.append(round(location.loc[idnr,best_match]/verdeelsleutel_location,3))\n",
    "    list_holder_name.append(round(name.loc[idnr,best_match]/verdeelsleutel_name,3))\n",
    "    list_holder_attr.append(round(listing_attributes.loc[idnr,best_match]/verdeelsleutel_listing_attributes,3))\n",
    "    list_holder_desc.append(round(description.loc[idnr,best_match] / verdeelsleutel_description,3))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['feature_listing_attributes'] = list_holder_attr\n",
    "match_df['feature_price'] = list_holder_price \n",
    "match_df['feature_name'] = list_holder_name  \n",
    "match_df['feature_description'] = list_holder_desc  \n",
    "match_df['feature_location'] = list_holder_loc   \n",
    "match_df['duplicate_ID'] = range(1, len(match_df) + 1)\n",
    "match_df['type']  = 'listings'\n",
    "match_df['status']  = 'Undifined'\n",
    "match_df['timestamp'] = \"13-01-2019\"\n",
    "match_df.rename(columns = {'id':'case_A_id','best_matching_id':'case_B_id','match_value':'match_score'}, inplace = True)\n",
    "output =match_df[[\"duplicate_ID\",\"type\",\"case_A_id\",\"case_B_id\",\"match_score\", \"status\", \"timestamp\", \"feature_listing_attributes\",'feature_price','feature_name','feature_location','feature_description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cond = (output.case_A_id.shift(1) == output.case_B_id)\n",
    "output['Result'] = np.where(y_cond, 'Y', 'N')\n",
    "output = output[output['Result']== 'Y' ]\n",
    "output =output.iloc[:,:-1]  ## Remove the result column , which indicates if their is a dubblicate match\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings[df_listings['id']== 22556265]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_listings[df_listings['id']== 22556393]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_json('duplicates_nieuwe_verdeelsleutel1.js' ,orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
